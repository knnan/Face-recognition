{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from MTCNN_face_detection import extract_face\n",
    "from matplotlib import pyplot\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from faced import FaceDetector\n",
    "from faced.utils import annotate_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jeloo\n"
     ]
    }
   ],
   "source": [
    "# specify folder to plot\n",
    "folder = '/home/knnan/Development/face_recognition/unknown_faces/Abdullah/'\n",
    "print(\"jeloo\")\n",
    "cascade_path = '/home/knnan/Development/face_recognition/keras-facenet/model/cv2/haarcascade_frontalface_alt2.xml'\n",
    "cascade = cv2.CascadeClassifier(cascade_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtcnn_detect_face(folder):\n",
    "    i = 1\n",
    "    # enumerate files\n",
    "    for filename in listdir(folder):\n",
    "        # path\n",
    "        path = folder + filename\n",
    "        # get face\n",
    "        \n",
    "        face = extract_face(path)\n",
    "        print(i, face.shape)\n",
    "        # plot\n",
    "        pyplot.subplot(2, 7, i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(face)\n",
    "#         cv2.imshow(face)\n",
    "        i += 1\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_detect_face(folder):\n",
    "    imgs = []\n",
    "    i = 1\n",
    "    # enumerate files\n",
    "#     for filename in listdir(folder):\n",
    "        # path\n",
    "#     path = folder + filename\n",
    "    path = '/home/knnan/Development/face_recognition/unknown_faces/Hameem/Hameem1.jpg'\n",
    "    print(path)\n",
    "    # get face\n",
    "    frame = cv2.imread(path)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = cascade.detectMultiScale(frame,scaleFactor=1.1,minNeighbors=3,minSize=(100, 100))\n",
    "    if len(faces) != 0:\n",
    "            print(\"hello\")\n",
    "            face = faces[0]\n",
    "            (x, y, w, h) = face\n",
    "            left = x - 10 // 2\n",
    "            right = x + w + 10 // 2\n",
    "            bottom = y - 10 // 2\n",
    "            top = y + h + 10 // 2\n",
    "            img = resize(frame[bottom:top, left:right, :],\n",
    "                         (160, 160), mode='reflect')\n",
    "            print(img)\n",
    "            imgs.append(img)\n",
    "            cv2.rectangle(frame,\n",
    "                          (left-1, bottom-1),\n",
    "                          (right+1, top+1),\n",
    "                          (255, 0, 0), thickness=2)\n",
    "            \n",
    "\n",
    "            pyplot.imshow(frame)\n",
    "            pyplot.title('{}/{}'.format(len(imgs), 10))\n",
    "            pyplot.xticks([])\n",
    "            pyplot.yticks([])\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faced_dector():\n",
    "    print(\"hs ddd\")\n",
    "\n",
    "\n",
    "\n",
    "    face_detector = FaceDetector()\n",
    "    img_path = '/home/knnan/Development/face_recognition/unknown_faces/multiple_faces/ab_ha.png'\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Receives RGB numpy image (HxWxC) and\n",
    "    # returns (x_center, y_center, width, height, prob) tuples. \n",
    "    bboxes = face_detector.predict(rgb_img)\n",
    "\n",
    "    # Use this utils function to annotate the image.\n",
    "    ann_img = annotate_image(img, bboxes)\n",
    "    print(ann_img)\n",
    "    cv2.imshow('image',ann_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faced_vid_dector():\n",
    "    print(\"vid has started\")\n",
    "    face_detector = FaceDetector()\n",
    "    video_capture = cv2.VideoCapture('rtsp://admin:Unique123@106.51.130.230:554/Streaming/Channels/1')\n",
    "    required_size = (160, 160)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        rgb_img = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2RGB)\n",
    "        bboxes = face_detector.predict(rgb_img)\n",
    "        ann_img = annotate_image(frame, bboxes)\n",
    "        cv2.imshow('Video',ann_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its starting\n"
     ]
    }
   ],
   "source": [
    "print('its starting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "1 (160, 160, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "imshow() missing required argument 'mat' (pos 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d020a63a1b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmtcnn_detect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# faced_dector()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# faced_vid_dector()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-20cdca64b8cf>\u001b[0m in \u001b[0;36mmtcnn_detect_face\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         pyplot.imshow(face)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: imshow() missing required argument 'mat' (pos 2)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADcAAABxCAYAAABx2js3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAAmklEQVR4nO3PAQ3AMAzAsH38OfcorstVjCB5ZuZsdf8O+FJzquZUzamaUzWnak7VnKo5VXOq5lTNqZpTNadqTtWcqjlVc6rmVM2pmlM1p2pO1ZyqOVVzquZUzamaUzWnak7VnKo5VXOq5lTNqZpTNadqTtWcqjlVc6rmVM2pmlM1p2pO1ZyqOVVzquZUzamaUzWnak7VnGr13AsAygPfqfCDcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mtcnn_detect_face(folder)\n",
    "# faced_dector()\n",
    "# faced_vid_dector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Started execution')\n",
    "# import cv2\n",
    "# from faced import FaceDetector\n",
    "# from faced.utils import annotate_image\n",
    "# face_detector = FaceDetector()\n",
    "# img_path = '/home/knnan/Development/face_recognition/unknown_faces/multiple_faces/ab_ha.png'\n",
    "\n",
    "# img = cv2.imread(img_path)\n",
    "# rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Receives RGB numpy image (HxWxC) and\n",
    "# # returns (x_center, y_center, width, height, prob) tuples. \n",
    "# bboxes = face_detector.predict(rgb_img)\n",
    "# print('No of faces : ',len(bboxes))\n",
    "# # Use this utils function to annotate the image.\n",
    "# ann_img = annotate_image(img, bboxes)\n",
    "# ann_img = cv2.resize(ann_img,(600,600))\n",
    "# cv2.imshow('image',ann_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# print(\"Finished execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
