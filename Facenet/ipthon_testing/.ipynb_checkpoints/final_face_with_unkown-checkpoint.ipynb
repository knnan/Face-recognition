{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import os\n",
    "from time import perf_counter\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "import math\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from random import choice\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from os import listdir\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "from faced import FaceDetector\n",
    "from faced.utils import annotate_image\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "# Global variables and definitions\n",
    "face_detector = FaceDetector()\n",
    "model_path = '/home/knnan/Development/face_recognition/Facenet/keras-facenet/model/facenet_keras.h5'\n",
    "model = load_model(model_path)\n",
    "face_embeddings_file = '/home/knnan/Development/face_recognition/Facenet/all_faces_embeddings.npz'\n",
    "pre_embeddings_data = load(face_embeddings_file)\n",
    "print(\"Model has Loaded\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def euc(a,b):\n",
    "    dst = distance.euclidean(a, b)\n",
    "    return dst\n",
    "\n",
    "def display_multi_images(images_array):\n",
    "    f = pyplot.figure(figsize=(20, 20))\n",
    "    columns = 3\n",
    "    rows = 1\n",
    "    image_index = 0\n",
    "    for i in range(1, columns*rows +1):\n",
    "        \n",
    "        if(image_index+1 > len(images_array)):\n",
    "            break\n",
    "        f.add_subplot(rows, columns, i)\n",
    "        pyplot.imshow(images_array[image_index])\n",
    "        image_index += 1\n",
    "     \n",
    "    pyplot.show()\n",
    "    \n",
    "def get_multi_embeddings(model, face_pixels_array):\n",
    "    embeddings_array = []\n",
    "    in_encoder = Normalizer(norm='l2')\n",
    "    for face_pixels in face_pixels_array:\n",
    "        face_pixels = face_pixels.astype('float32')\n",
    "        # standardize pixel values across channels (global)\n",
    "        mean, std = face_pixels.mean(), face_pixels.std()\n",
    "        face_pixels = (face_pixels - mean) / std\n",
    "        # transform face into one sample\n",
    "        samples = expand_dims(face_pixels, axis=0)\n",
    "        # make prediction to get embedding\n",
    "        yhat = model.predict(samples)\n",
    "        # return back face embedding\n",
    "        embeddings_array.append(yhat[0])\n",
    "        \n",
    "    print('No of embeddings : ',len(embeddings_array))\n",
    "    return in_encoder.transform(embeddings_array)\n",
    "\n",
    "\n",
    "\n",
    "def calVecdist(listvec,emb):\n",
    "    meanlist = []\n",
    "    for i in listvec:\n",
    "        print(euc(i,emb))\n",
    "        meanlist.append(euc(i,emb))\n",
    "    print('Average distance is ',np.mean(meanlist))\n",
    "    \n",
    "def getFaces(frame='/home/knnan/Development/face_recognition/unknown_faces/multiple_faces/ab_ha.png',type='image'):\n",
    "    cropped_faces = []\n",
    "    cordinates = []\n",
    "    multi_face_image = '/home/knnan/Development/face_recognition/unknown_faces/multiple_faces/ab_ha.png'\n",
    "    required_size = (160, 160)\n",
    "    original_image = frame\n",
    "    if(type == 'image'):\n",
    "        original_image = cv2.imread(frame)\n",
    "    rgb_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    pixels = rgb_image\n",
    "    bboxes = face_detector.predict(pixels)\n",
    "    print(\"No of Faces Detected : \",len(bboxes))\n",
    "    \n",
    "\n",
    "    ann_image = annotate_image(original_image.copy(), bboxes)\n",
    "    for bbox  in bboxes:\n",
    "        x, y, width, height,p = bbox\n",
    "        print('probability : ',p)\n",
    "        if p < 0.70:\n",
    "            continue\n",
    "\n",
    "        x1 = int(x - width/2)\n",
    "        y1 = int(y - height/2)\n",
    "        x2 = int(x + width/2)\n",
    "        y2 = int(y + height/2)\n",
    "        cordinates.append((x1,y1,x2,y2))\n",
    "\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        single_face_array = asarray(image)\n",
    "        cropped_faces.append(single_face_array)\n",
    "    print('No of cropped_faces : ',len(cropped_faces))\n",
    "#     display_multi_images(cropped_faces)\n",
    "    return [cropped_faces,cordinates,original_image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_embeddings_file = '/home/knnan/Development/face_recognition/Facenet/all_faces_embeddings.npz'\n",
    "    \n",
    "data = load(face_embeddings_file)\n",
    "face_detector = FaceDetector()\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components=3).fit(trainX)\n",
    "\n",
    "X_Hameem = []\n",
    "X_Munirul = []\n",
    "X_Abdullah = []\n",
    "X_Nishad = []\n",
    "X_toufiq = []\n",
    "X_unown = []\n",
    "\n",
    "X_unown.append(embedding)\n",
    "\n",
    "for emb,name in zip(trainX,trainy):\n",
    "    if name == 'Hameem':\n",
    "        X_Hameem.append(emb)\n",
    "    elif name == 'munirul':\n",
    "        X_Munirul.append(emb)\n",
    "    elif name == 'Abdullah':\n",
    "        X_Abdullah.append(emb)\n",
    "    elif name == 'Nishad':\n",
    "        X_Nishad.append(emb)\n",
    "    elif name == 'toufiq':\n",
    "        X_toufiq.append(emb)\n",
    "\n",
    "Xd_Hameem = pca.transform(X_Hameem)\n",
    "Xd_Abdullah = pca.transform(X_Abdullah)\n",
    "Xd_Munirul = pca.transform(X_Munirul)\n",
    "Xd_Nishad = pca.transform(X_Nishad)\n",
    "Xd_toufiq = pca.transform(X_toufiq)\n",
    "Xd_unown = pca.transform(X_unown)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.rcParams['legend.fontsize'] = 10   \n",
    "ax.plot(Xd_Hameem[:,0], Xd_Hameem[:,1], Xd_Hameem[:,2],\n",
    "        'o', markersize=8, color='blue', alpha=0.5, label='Hameem')\n",
    "ax.plot(Xd_Abdullah[:,0], Xd_Abdullah[:,1], Xd_Abdullah[:,2],\n",
    "        'o', markersize=8, color='red', alpha=0.5, label='Abdullah')\n",
    "ax.plot(Xd_Munirul[:,0], Xd_Munirul[:,1], Xd_Munirul[:,2],\n",
    "        'o', markersize=8, color='green', alpha=0.5, label='Munirul')\n",
    "ax.plot(Xd_Nishad[:,0], Xd_Nishad[:,1], Xd_Nishad[:,2],\n",
    "        'o', markersize=8, color='yellow', alpha=0.5, label='Nishad')\n",
    "ax.plot(Xd_unown[:,0], Xd_unown[:,1], Xd_unown[:,2],\n",
    "        'o', markersize=8, color='black', alpha=0.5, label='unown')\n",
    "\n",
    "plt.title('Embedding Vector')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "svcmodel = SVC(kernel='linear', probability=True)\n",
    "svcmodel.fit(trainX, trainy)\n",
    "# predict\n",
    "yhat_train = svcmodel.predict(trainX)\n",
    "yhat_test = svcmodel.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_plot(prediction,embedding):\n",
    "  \n",
    "\n",
    "    ax.clear()\n",
    "    ax.plot(Xd_Hameem[:,0], Xd_Hameem[:,1], Xd_Hameem[:,2],\n",
    "            'o', markersize=8, color='blue', alpha=0.5, label='Hameem')\n",
    "    ax.plot(Xd_Abdullah[:,0], Xd_Abdullah[:,1], Xd_Abdullah[:,2],\n",
    "            'o', markersize=8, color='red', alpha=0.5, label='Abdullah')\n",
    "    ax.plot(Xd_Munirul[:,0], Xd_Munirul[:,1], Xd_Munirul[:,2],\n",
    "            'o', markersize=8, color='green', alpha=0.5, label='Munirul')\n",
    "    ax.plot(Xd_Nishad[:,0], Xd_Nishad[:,1], Xd_Nishad[:,2],\n",
    "            'o', markersize=8, color='yellow', alpha=0.5, label='Nishad')\n",
    "    ax.plot(Xd_unown[:,0], Xd_unown[:,1], Xd_unown[:,2],\n",
    "            'o', markersize=8, color='black', alpha=0.5, label='unown')\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "    \n",
    "    \n",
    "def calman(prediction,embedding):\n",
    "    X_unown = []\n",
    "    X_unown.append(embedding)\n",
    "    Xd_unown = pca.transform(X_unown)\n",
    "    if prediction == 'Hameem':\n",
    "        calVecdist(Xd_Hameem,Xd_unown)\n",
    "    elif prediction == 'munirul':\n",
    "        calVecdist(Xd_Munirul,Xd_unown)\n",
    "    elif prediction == 'Abdullah':\n",
    "        calVecdist(Xd_Abdullah,Xd_unown)\n",
    "    elif prediction == 'Nishad':\n",
    "        calVecdist(Xd_Nishad,Xd_unown)\n",
    "    elif prediction == 'toufiq':\n",
    "        calVecdist(Xd_toufiq,Xd_unown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "video_file_path = ''\n",
    "video_capture = cv2.VideoCapture(video_file_path)\n",
    "frame_count = 1\n",
    "while (video_capture.isOpened()):\n",
    "\n",
    "\n",
    "    start = timer()\n",
    "    ret, frame = video_capture.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    original_image = frame.copy()\n",
    "    all_faces_array,all_cordinates,original_image = getFaces(original_image,'video')\n",
    "    if (len(all_faces_array) < 1):\n",
    "        continue\n",
    "    all_face_embeddings = get_multi_embeddings(model,all_faces_array)\n",
    "\n",
    "    for single_face_embedding,single_cordinate in zip(all_face_embeddings,all_cordinates):\n",
    "        left,top,right,bottom = single_cordinate\n",
    "        samples = expand_dims(single_face_embedding, axis=0)\n",
    "        yhat_class = svcmodel.predict(samples)\n",
    "        yhat_prob = svcmodel.predict_proba(samples)\n",
    "\n",
    "\n",
    "        class_index = yhat_class[0]\n",
    "        class_probability = yhat_prob[0,class_index] * 100\n",
    "        predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "        guessed_name = predict_names[0]\n",
    "        print(\"start distance cal\")\n",
    "        getdistances(guessed_name,single_face_embedding)\n",
    "        print(\"end distance calcul\")\n",
    "        print(\"PREDICTION : \",guessed_name,\"\\n percentange : \",class_probability)\n",
    "        cv2.rectangle(original_image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(original_image, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "        cv2.putText(original_image, guessed_name + '_' + str(class_probability), (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "    original_image = cv2.resize(original_image,(800,800))\n",
    "\n",
    "    cv2.imshow('Video', original_image)\n",
    "    frame_count = frame_count + 1\n",
    "    input(\"Press Enter to continue...\")\n",
    "    cv2.waitKey(0)\n",
    "    clear_output()\n",
    "\n",
    "    \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
